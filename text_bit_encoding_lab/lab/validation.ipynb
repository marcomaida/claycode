{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-Bit Encoding Validation\n",
    "\n",
    "In this notebook, we check that the text-bit encoding is working properly. \n",
    "\n",
    "First, we define some helper functions to test the encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../')\n",
    "from text_bit.dataset import read_datasets\n",
    "\n",
    "datasets = read_datasets(\"../datasets/\")\n",
    "\n",
    "# Given a dataset, a `text_to_bit`, and a `bit_to_text` function, \n",
    "# Tests that each string of the data set works when encoded and decoded.\n",
    "def expect_all_working(dataset, text_to_bit, bit_to_text):\n",
    "    for m in dataset:\n",
    "        try:\n",
    "            bits = text_to_bit(m)\n",
    "            assert bits is not None, f\"Is None: {m}\"\n",
    "            assert bit_to_text(bits) == m, f\"Does not match: {m}\"\n",
    "        except:\n",
    "            assert False, f\"Crashes: {m}\"\n",
    "\n",
    "# Given a dataset and a `text_to_bit` function, checks that each string\n",
    "# is not supported, i.e., the function must return `None`\n",
    "def expect_all_not_supported(dataset, text_to_bit):\n",
    "    for m in dataset:\n",
    "        try:\n",
    "            bits = text_to_bit(m)\n",
    "            assert bits is None, f\"Is not None: {m}\"\n",
    "        except:\n",
    "            assert False, f\"Crashes: {m}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Nat` Encoding\n",
    "\n",
    "`Nat` should only work on natural numbers without trailing zeroes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_bit.encodings.nat_number import NatNumberEncoding as NNE\n",
    "\n",
    "expect_all_working(datasets[\"nat\"], NNE.text_to_bit, NNE.bit_to_text)\n",
    "expect_all_not_supported(datasets[\"not_nat\"], NNE.text_to_bit)\n",
    "expect_all_not_supported(datasets[\"url\"], NNE.text_to_bit)\n",
    "expect_all_not_supported(datasets[\"text\"], NNE.text_to_bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{00000: 'a',\n",
       " 00001: 'b',\n",
       " 00010: 'c',\n",
       " 00011: 'd',\n",
       " 00100: 'e',\n",
       " 00101: 'f',\n",
       " 00110: 'g',\n",
       " 001110: 'h',\n",
       " 001111: 'i',\n",
       " 01000: 'j',\n",
       " 01001: 'k',\n",
       " 01010: 'l',\n",
       " 01011: 'm',\n",
       " 01100: 'n',\n",
       " 01101: 'o',\n",
       " 01110: 'p',\n",
       " 011110: 'q',\n",
       " 011111: 'r',\n",
       " 10000: 's',\n",
       " 10001: 't',\n",
       " 10010: 'u',\n",
       " 10011: 'v',\n",
       " 10100: 'w',\n",
       " 10101: 'x',\n",
       " 10110: 'y',\n",
       " 101110: 'z',\n",
       " 101111: '0',\n",
       " 11000: '1',\n",
       " 11001: '2',\n",
       " 11010: '3',\n",
       " 110110: '4',\n",
       " 110111: '5',\n",
       " 11100: '6',\n",
       " 11101: '7',\n",
       " 11110: '8',\n",
       " 111110: '9',\n",
       " 111111: '.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text_bit.huffmann_tree import HuffmannTree\n",
    "\n",
    "defalphanumeric =   [[[[['a', ['b', 'c']], [['d', 'e'], ['f', 'g']]],\n",
    "                    [[['h', 'i'], ['j', 'k']], [['l', 'm'], ['n', 'o']]]],\n",
    "                    [[[['p', 'q'], ['r', 's']], [['t', 'u'], ['v', 'w']]],\n",
    "                    [[['x', 'y'], ['z', 'A']], [['B', 'C'], ['D', 'E']]]]],\n",
    "                    [[[['F', ['G', 'H']], [['I', 'J'], ['K', 'L']]],\n",
    "                    [[['M', 'N'], ['O', 'P']], [['Q', 'R'], ['S', 'T']]]],\n",
    "                    [[[['U', 'V'], ['W', 'X']], [['Y', 'Z'], ['0', '1']]],\n",
    "                    [[['2', '3'], ['4', '5']], [['6', '7'], ['8', '9']]]]]];\n",
    "\n",
    "# defalphanumeric = [[[[['a', 'b'], ['c', 'd']], [['e', 'f'], ['g', ['h', 'i']]]],\n",
    "#                   [[['j', 'k'], ['l', 'm']], [['n', 'o'], ['p', ['q', 'r']]]]],\n",
    "#                   [[[['s', 't'], ['u', 'v']], [['w', 'x'], ['y', ['z', '0']]]],\n",
    "#                   [[['1', '2'], ['3', ['4', '5']]], [['6', '7'], ['8', ['9', '.']]]]]]\n",
    "\n",
    "ht = HuffmannTree(defalphanumeric)\n",
    "# https://www.example.com:443/resources/newpage.html?key1=value1&key2=value2#faq\n",
    "\n",
    "ht.elements_by_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing all datasets to validate umbrella encoding...\n"
     ]
    }
   ],
   "source": [
    "from text_bit.encodings.umbrella import UmbrellaEncoding as UE\n",
    "\n",
    "print(\"Testing all datasets to validate umbrella encoding...\")\n",
    "for ds in datasets.values(): expect_all_working(ds, UE.text_to_bit, UE.bit_to_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "01111001011010001100110011011010"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from text_bit.bit_string import BitString\n",
    "from text_bit.crc import Crc\n",
    "\n",
    "bs = BitString(\"11111111\")\n",
    "crc = Crc(Crc.POLY32_IEEE, 32)\n",
    "crc.compute_crc(bs)\n",
    "\n",
    "# 0b11111111000000000000000000000000 expected, TODO FIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Encoding\n",
    "\n",
    "#### Prefix Code\n",
    "\n",
    "The _Prefix Code_ is the basic building block of a multimodal encoding. It uses a full binary tree with an element as leaf. \n",
    "\n",
    "A multimodal encoding uses a tree of encodings. \n",
    "\n",
    "The beginning of the message tells which encoding must be applied. E.g., consider a multimodal encoding that supports 3 encodings, A, B, and C. We can map the encoding to the following tree:\n",
    "\n",
    "```\n",
    "  .        If the message starts with...        \n",
    " / \\                     0... => Use encoding A \n",
    "A   .                    10...=> Use encoding B \n",
    "   / \\                   11...=> Use encoding C \n",
    "  B   C                                         \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_bit.prefix_code import prefix_code_unit_test\n",
    "\n",
    "prefix_code_unit_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multimodal Encoding\n",
    "\n",
    "We now test that some multimodal encodings work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_bit.encodings.umbrella import UmbrellaEncoding as UE\n",
    "from text_bit.encodings.nat_number import NatNumberEncoding as NNE\n",
    "from text_bit.multimodal_encoding import MultimodalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_bit.encodings.umbrella import UmbrellaEncoding as UE\n",
    "from text_bit.encodings.nat_number import NatNumberEncoding as NNE\n",
    "from text_bit.multimodal_encoding import MultimodalEncoding\n",
    "\n",
    "# Basic multimodal encoding: just use umbrella\n",
    "me_umbrella = MultimodalEncoding(\"umbrella\", UE)\n",
    "for ds in datasets.values(): expect_all_working(ds, me_umbrella.text_to_bit, me_umbrella.bit_to_text)\n",
    "\n",
    "# Multimodal encoding with two encoding, nats and umbrella\n",
    "me_two = MultimodalEncoding(\"two\", [NNE, UE])\n",
    "for ds in datasets.values(): expect_all_working(ds, me_two.text_to_bit, me_two.bit_to_text)\n",
    "\n",
    "# More complex multimodal encoding, some reserved values\n",
    "me_none = MultimodalEncoding(\"complex\", [None, [None, [NNE, [None, UE]]]])\n",
    "for ds in datasets.values(): expect_all_working(ds, me_none.text_to_bit, me_none.bit_to_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
