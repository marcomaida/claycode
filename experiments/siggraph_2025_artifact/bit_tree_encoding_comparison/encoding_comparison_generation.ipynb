{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Comparison Generation\n",
    "\n",
    "This notebook generates the dataset for a side-by-side evaluation of different bit-to-tree encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "import traceback\n",
    "\n",
    "from tree_lib.tree import TreeNode, tower\n",
    "from tree_lib.encodings import two_choices, two_choices_one_two, counting_ones, counting_ones_leaves, fibonaccio, tuples, square, cube, entropy, power_digits, power_digits_2, gauss, cantor2d, simplex, one_child, abe1993\n",
    "import tree_lib.util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 - Define encodings to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ENCODINGS_UNFILTERED = [\n",
    "    #### Display  | bits to tree | tree to bits | max bits encodable (None if infinite)\n",
    "    # [\"n*(n+1)/2\", gauss.bits_to_tree, gauss.tree_to_bits,None],\n",
    "    # [\"two_choices\", two_choices.bits_to_tree, two_choices.tree_to_bits,None],\n",
    "    # [\"two_choices_one_two\", two_choices_one_two.bits_to_tree, two_choices_one_two.tree_to_bits,None],\n",
    "    # [\"two_choices_wrap\", two_choices.bits_to_tree_wrap, None,None],\n",
    "    # [\"two_choices_mark\", two_choices.bits_to_tree_mark, None,None],\n",
    "    # [\"two_choices_k=9\", lambda s: two_choices.bits_to_tree_k(s, 9), None,None],\n",
    "    # [\"counting_ones_leaves\", counting_ones_leaves.bits_to_tree, counting_ones_leaves.tree_to_bits,None],\n",
    "    # [\"fibonaccio\", fibonaccio.bits_to_tree, fibonaccio.tree_to_bits,None],\n",
    "    # [\"power_digits\", power_digits.bits_to_tree, power_digits.tree_to_bits,None],\n",
    "    # [\"power_digits_2\", power_digits_2.bits_to_tree, power_digits_2.tree_to_bits,None],\n",
    "    # [\"tuples\", tuples.bits_to_tree, tuples.tree_to_bits,None],\n",
    "    [\"Y.Abe, 1994\", abe1993.bits_to_tree, abe1993.tree_to_bits,31],\n",
    "    [\"Squares\", square.bits_to_tree, square.tree_to_bits,None],\n",
    "    [\"Cubes\", cube.bits_to_tree, cube.tree_to_bits,None],\n",
    "    # [\"entropy\", entropy.bits_to_tree, entropy.tree_to_bits,None],\n",
    "    # [\"cantor2d\", cantor2d.bits_to_tree, cantor2d.tree_to_bits,None],\n",
    "    # [\"cantor2d_snake\", lambda s: cantor2d.bits_to_tree(s, snake=True), lambda t: cantor2d.tree_to_bits(t, snake=True),None],\n",
    "    # [\"simplex2d\", lambda s: simplex.bits_to_tree(s, 2), lambda t: simplex.tree_to_bits(t, 2),None],\n",
    "    # [\"simplex3d\", lambda s: simplex.bits_to_tree(s, 3), lambda t: simplex.tree_to_bits(t, 3),None],\n",
    "    # [\"one_child\", one_child.bits_to_tree, one_child.tree_to_bits,None],\n",
    "    # [\"simplex4d\", lambda s: simplex.bits_to_tree(s, 4), lambda t: simplex.tree_to_bits(t, 4),None],\n",
    "    # [\"simplex5d\", lambda s: simplex.bits_to_tree(s, 5), lambda t: simplex.tree_to_bits(t, 5),None],\n",
    "    # [\"simplex10d\", lambda s: simplex.bits_to_tree(s, 10), lambda t: simplex.tree_to_bits(t, 10),None],\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Check for correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.Abe, 1994: Keeping only 12/12 strings -- length <= 31\n",
      "Y.Abe, 1994: Keeping only 30/399 strings -- length <= 31\n",
      "Y.Abe, 1994: Keeping only 42/411 strings -- length <= 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Basic Test</th>\n",
       "      <th>Long Strings</th>\n",
       "      <th>Unordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y.Abe, 1994</td>\n",
       "      <td>✅</td>\n",
       "      <td>✅</td>\n",
       "      <td>✅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Squares</td>\n",
       "      <td>✅</td>\n",
       "      <td>✅</td>\n",
       "      <td>✅</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cubes</td>\n",
       "      <td>✅</td>\n",
       "      <td>✅</td>\n",
       "      <td>✅</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name Basic Test Long Strings Unordered\n",
       "0  Y.Abe, 1994          ✅            ✅         ✅\n",
       "1      Squares          ✅            ✅         ✅\n",
       "2        Cubes          ✅            ✅         ✅"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "\n",
    "BASIC_STRINGS = [\n",
    "    \"0\",\"1\",\"01\",\"10\",\"11\", \"100\", \"101\", \"110\", \"111\",     # basic\n",
    "    \"010101010101\", \"0000000000\", \"1111111111\",             # something more complex\n",
    "]\n",
    "LONG_STRINGS = [util.gen_bit_string(i) for i in range(1, 400)]\n",
    "\n",
    "def string_test(strings, name, btt, ttb, max_bits, shuffle=False):\n",
    "    def encode_decode(s):\n",
    "        t = btt(s)\n",
    "        if t is not None and shuffle:\n",
    "            util.shuffle_tree(t)\n",
    "        return ttb(t)\n",
    "    \n",
    "    # Filter out strings for encodings that have limited capabilities\n",
    "    if max_bits is not None:\n",
    "        orig_strings_len = len(strings)\n",
    "        strings = [s for s in strings if len(s) < max_bits]\n",
    "        print(f\"{name}: Keeping only {len(strings)}/{orig_strings_len} strings -- length <= {max_bits}\")\n",
    "\n",
    "    try:\n",
    "        if ttb is None:\n",
    "            # If there is no ttb, try to encode strings only\n",
    "            res = [btt(s) for s in strings]\n",
    "            return f\"🤷️️️️️️\"\n",
    "        else:\n",
    "            errors = func_timeout(10., lambda: [s for s in strings if encode_decode(s) != s])\n",
    "            return \"✅\" if len(errors)==0 else f\"🐖️️️️️️ {errors[0]}\"\n",
    "    except FunctionTimedOut:\n",
    "        return f\"⏰\"\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "        return f\"🧨️️️️️️ {e}\"\n",
    "\n",
    "results = [[name, \n",
    "            string_test(BASIC_STRINGS, name, btt, ttb, max_bits), \n",
    "            string_test(LONG_STRINGS, name, btt, ttb, max_bits),\n",
    "            string_test(BASIC_STRINGS+LONG_STRINGS, name, btt, ttb, max_bits, True),] \n",
    "            for name, btt, ttb, max_bits in ENCODINGS_UNFILTERED]\n",
    "\n",
    "df = pd.DataFrame(results, columns=['Name', 'Basic Test', \"Long Strings\", \"Unordered\"])\n",
    "\n",
    "# Discard encodings that do not work\n",
    "def is_acceptable_result(test_basic,test_long,test_unordered):\n",
    "    return (\"✅\" in test_basic or \"🤷️️️️️\" in test_basic) and \\\n",
    "           (\"✅\" in test_long or \"🤷️️️️️\" in test_long)\n",
    "\n",
    "to_discard = [name for [name, t1, t2, t3] in results if not is_acceptable_result(t1,t2,t3)]\n",
    "if to_discard:\n",
    "    print(f\"\\nDiscarding {to_discard}\")\n",
    "ENCODINGS = [e for e in ENCODINGS_UNFILTERED if e[0] not in to_discard]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Generate dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63000\n",
      "63020\n",
      "90020\n",
      "Y.Abe, 1994: Keeping only 27006/90020 strings -- length <= 31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Encoding</th>\n",
       "      <th>Bits</th>\n",
       "      <th>PercOfOnes</th>\n",
       "      <th>Autocorrelation</th>\n",
       "      <th>Nodes/Bit</th>\n",
       "      <th>Footprint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y.Abe, 1994</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.10</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y.Abe, 1994</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Y.Abe, 1994</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.20</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Y.Abe, 1994</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Y.Abe, 1994</td>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.20</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207041</th>\n",
       "      <td>Cubes</td>\n",
       "      <td>100</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.63</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207042</th>\n",
       "      <td>Cubes</td>\n",
       "      <td>100</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.62</td>\n",
       "      <td>619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207043</th>\n",
       "      <td>Cubes</td>\n",
       "      <td>100</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.86</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207044</th>\n",
       "      <td>Cubes</td>\n",
       "      <td>100</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.99</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207045</th>\n",
       "      <td>Cubes</td>\n",
       "      <td>100</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.71</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207046 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Encoding  Bits  PercOfOnes  Autocorrelation  Nodes/Bit  Footprint\n",
       "0       Y.Abe, 1994    10        0.10             0.80       1.10         28\n",
       "1       Y.Abe, 1994    10        0.00             1.00       1.10         21\n",
       "2       Y.Abe, 1994    10        0.10             0.90       1.20         24\n",
       "3       Y.Abe, 1994    10        0.00             1.00       1.10         21\n",
       "4       Y.Abe, 1994    10        0.10             0.90       1.20         37\n",
       "...             ...   ...         ...              ...        ...        ...\n",
       "207041        Cubes   100        0.72             0.92       1.63        620\n",
       "207042        Cubes   100        0.79             0.93       1.62        619\n",
       "207043        Cubes   100        0.42             0.89       1.86        704\n",
       "207044        Cubes   100        0.43             0.92       1.99        746\n",
       "207045        Cubes   100        0.77             0.94       1.71        650\n",
       "\n",
       "[207046 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIT_STRING_LENGTHS = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "PROBABILITY_OF_ONE = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "AUTOCORRELATION = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "SAMPLES_PER_STRING_TYPE = 700\n",
    "SAMPLES_PER_STRING_TYPE_AC = 300\n",
    "\n",
    "# Build generic random data set with random string. \n",
    "dataset_generic = [util.gen_bit_string(length, prob_of_one) \n",
    "                        for length in BIT_STRING_LENGTHS \n",
    "                        for prob_of_one in PROBABILITY_OF_ONE\n",
    "                        for _ in range(SAMPLES_PER_STRING_TYPE)]\n",
    "print(len(dataset_generic))\n",
    "# Inject some edge cases (all zeros, all ones)\n",
    "dataset_generic += [util.gen_bit_string(length, prob_of_one) \n",
    "                        for length in BIT_STRING_LENGTHS \n",
    "                        for prob_of_one in [0., 1.]]    \n",
    "\n",
    "print(len(dataset_generic))\n",
    "\n",
    "dataset_generic += [util.gen_bit_string_with_autocorrelation(length, ac) \n",
    "                        for length in BIT_STRING_LENGTHS \n",
    "                        for ac in AUTOCORRELATION\n",
    "                        for _ in range(SAMPLES_PER_STRING_TYPE_AC)]              \n",
    "print(len(dataset_generic))\n",
    "\n",
    "def dataset_for_encoding (encoding_name, bit_to_tree_fun, max_bits): \n",
    "    filtered_dataset = dataset_generic\n",
    "    if max_bits is not None:\n",
    "        orig_strings_len = len(filtered_dataset)\n",
    "        filtered_dataset = [s for s in filtered_dataset if len(s) < max_bits]\n",
    "        print(f\"{encoding_name}: Keeping only {len(filtered_dataset)}/{orig_strings_len} strings -- length <= {max_bits}\")\n",
    "\n",
    "    # Generate random bit strings with various properties\n",
    "    # Given a bit string, generate a data point\n",
    "    # [encoding name, length, num nodes]\n",
    "    def data_point(bit_str):\n",
    "        tree = bit_to_tree_fun(bit_str)\n",
    "        str_len = len(bit_str)\n",
    "        perc_of_ones = bit_str.count('1') / str_len\n",
    "        autocorrelation = util.autocorrelation(bit_str)\n",
    "        return [encoding_name, str_len, perc_of_ones, autocorrelation, tree.n_descendants/str_len, tree.get_total_footprint()]\n",
    "    \n",
    "    return [data_point(bit_str) for bit_str in filtered_dataset]\n",
    "\n",
    "dataset = []\n",
    "for encoding_name, btt, _, max_bits in ENCODINGS:\n",
    "    dataset += dataset_for_encoding(encoding_name, btt, max_bits)\n",
    "\n",
    "df = pd.DataFrame(dataset, columns=['Encoding', 'Bits', 'PercOfOnes', 'Autocorrelation', 'Nodes/Bit', 'Footprint']) \n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"encoding_comparison.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
